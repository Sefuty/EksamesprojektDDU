<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>YOLOv8 Object Detection</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script>
        // Configure ONNX Runtime Web
        ort.env.wasm.numThreads = 1;
        ort.env.wasm.simd = true;
    </script>
    <style>
      canvas {
          display:block;
          border: 1px solid black;
          margin-top:10px;
      }
      #uploadInput {
          margin: 10px 0;
      }
      #status {
          color: #666;
          margin: 10px 0;
      }
    </style>
</head>
<body>
    <input id="uploadInput" type="file" accept="image/*"/>
    <div id="status">Ready to detect objects</div>
    <canvas></canvas>
    <script>
      /**
       * "Upload" button onClick handler: uploads selected image file
       * to backend, receives array of detected objects
       * and draws them on top of image
       */
       const input = document.getElementById("uploadInput");
       input.addEventListener("change",async(event) => {
           const boxes = await detect_objects_on_image(event.target.files[0]);
           draw_image_and_boxes(event.target.files[0],boxes);
       })

      /**
       * Function draws the image from provided file
       * and bounding boxes of detected objects on
       * top of the image
       * @param file Uploaded file object
       * @param boxes Array of bounding boxes in format [[x1,y1,x2,y2,object_type,probability],...]
       */
      function draw_image_and_boxes(file,boxes) {
          const img = new Image()
          img.src = URL.createObjectURL(file);
          img.onload = () => {
              const canvas = document.querySelector("canvas");
              canvas.width = img.width;
              canvas.height = img.height;
              const ctx = canvas.getContext("2d");
              ctx.drawImage(img,0,0);
              ctx.strokeStyle = "#00FF00";
              ctx.lineWidth = 3;
              ctx.font = "18px serif";
              boxes.forEach(([x1,y1,x2,y2,label]) => {
                  ctx.strokeRect(x1,y1,x2-x1,y2-y1);
                  ctx.fillStyle = "#00ff00";
                  const width = ctx.measureText(label).width;
                  ctx.fillRect(x1,y1,width+10,25);
                  ctx.fillStyle = "#000000";
                  ctx.fillText(label, x1, y1+18);
              });
          }
      }

      /**
       * Function receives an image, passes it through YOLOv8 neural network
       * and returns an array of detected objects and their bounding boxes
       * @param buf Input image body
       * @returns Array of bounding boxes in format [[x1,y1,x2,y2,object_type,probability],..]
       */
      async function detect_objects_on_image(buf) {
          const [input,img_width,img_height] = await prepare_input(buf);
          const output = await run_model(input);
          return process_output(output,img_width,img_height);
      }

      /**
       * Function used to convert input image to tensor,
       * required as an input to YOLOv8 object detection
       * network.
       * @param buf Content of uploaded file
       * @returns Array of pixels
       */
      async function prepare_input(buf) {
          return new Promise(resolve => {
              const img = new Image();
              img.src = URL.createObjectURL(buf);
              img.onload = () => {
                  const [img_width, img_height] = [img.width, img.height];
                  const canvas = document.createElement("canvas");
                  canvas.width = 640;
                  canvas.height = 640;
                  const context = canvas.getContext("2d");
                  
                  // Maintain aspect ratio
                  const scale = Math.min(640 / img.width, 640 / img.height);
                  const scaledWidth = img.width * scale;
                  const scaledHeight = img.height * scale;
                  const x = (640 - scaledWidth) / 2;
                  const y = (640 - scaledHeight) / 2;
                  
                  // Fill with black background
                  context.fillStyle = "#000000";
                  context.fillRect(0, 0, 640, 640);
                  
                  // Draw image centered
                  context.drawImage(img, x, y, scaledWidth, scaledHeight);
                  
                  const imgData = context.getImageData(0, 0, 640, 640);
                  const pixels = imgData.data;

                  // Convert to float32 array for better performance
                  const input = new Float32Array(3 * 640 * 640);
                  for (let i = 0; i < 640 * 640; i++) {
                      input[i] = pixels[i * 4] / 255.0;                    // R
                      input[i + 640 * 640] = pixels[i * 4 + 1] / 255.0;   // G
                      input[i + 2 * 640 * 640] = pixels[i * 4 + 2] / 255.0; // B
                  }
                  resolve([input, img_width, img_height]);
              };
          });
      }

      /**
       * Function used to pass provided input tensor to YOLOv8 neural network and return result
       * @param input Input pixels array
       * @returns Raw output of neural network as a flat array of numbers
       */
      async function run_model(input) {
          try {
              document.getElementById('status').textContent = 'Loading model...';
              const model = await ort.InferenceSession.create("best.onnx", {
                  executionProviders: ['wasm'],
                  graphOptimizationLevel: 'all'
              });
              
              document.getElementById('status').textContent = 'Processing image...';
              const tensor = new ort.Tensor('float32', input, [1, 3, 640, 640]);
              const outputs = await model.run({ images: tensor });
              return outputs["output0"].data;
          } catch (error) {
              console.error('Error running model:', error);
              document.getElementById('status').textContent = 'Error: ' + error.message;
              throw error;
          }
      }

      /**
       * Function used to convert RAW output from YOLOv8 to an array of detected objects.
       * Each object contain the bounding box of this object, the type of object and the probability
       * @param output Raw output of YOLOv8 network
       * @param img_width Width of original image
       * @param img_height Height of original image
       * @returns Array of detected objects in a format [[x1,y1,x2,y2,object_type,probability],..]
       */
      function process_output(output, img_width, img_height) {
          const boxes = [];
          const numClasses = 80;
          const numBoxes = 8400;
          
          for (let i = 0; i < numBoxes; i++) {
              let maxScore = 0;
              let maxClass = 0;
              
              // Find class with highest confidence
              for (let j = 0; j < numClasses; j++) {
                  const score = output[numBoxes * (j + 4) + i];
                  if (score > maxScore) {
                      maxScore = score;
                      maxClass = j;
                  }
              }
              
              if (maxScore < 0.5) continue;
              
              const xc = output[i];
              const yc = output[numBoxes + i];
              const w = output[2 * numBoxes + i];
              const h = output[3 * numBoxes + i];
              
              // Convert to pixel coordinates
              const x1 = Math.max(0, (xc - w/2) / 640 * img_width);
              const y1 = Math.max(0, (yc - h/2) / 640 * img_height);
              const x2 = Math.min(img_width, (xc + w/2) / 640 * img_width);
              const y2 = Math.min(img_height, (yc + h/2) / 640 * img_height);
              
              boxes.push([x1, y1, x2, y2, yolo_classes[maxClass], maxScore]);
          }
          
          // Sort by confidence and apply NMS
          boxes.sort((a, b) => b[5] - a[5]);
          const result = [];
          
          while (boxes.length > 0) {
              result.push(boxes[0]);
              boxes.splice(0, 1);
              
              let i = 0;
              while (i < boxes.length) {
                  if (iou(boxes[0], boxes[i]) > 0.7) {
                      boxes.splice(i, 1);
                  } else {
                      i++;
                  }
              }
          }
          
          return result;
      }

      /**
       * Function calculates "Intersection-over-union" coefficient for specified two boxes
       * https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/.
       * @param box1 First box in format: [x1,y1,x2,y2,object_class,probability]
       * @param box2 Second box in format: [x1,y1,x2,y2,object_class,probability]
       * @returns Intersection over union ratio as a float number
       */
      function iou(box1,box2) {
          return intersection(box1,box2)/union(box1,box2);
      }

      /**
       * Function calculates union area of two boxes.
       *     :param box1: First box in format [x1,y1,x2,y2,object_class,probability]
       *     :param box2: Second box in format [x1,y1,x2,y2,object_class,probability]
       *     :return: Area of the boxes union as a float number
       * @param box1 First box in format [x1,y1,x2,y2,object_class,probability]
       * @param box2 Second box in format [x1,y1,x2,y2,object_class,probability]
       * @returns Area of the boxes union as a float number
       */
      function union(box1,box2) {
          const [box1_x1,box1_y1,box1_x2,box1_y2] = box1;
          const [box2_x1,box2_y1,box2_x2,box2_y2] = box2;
          const box1_area = (box1_x2-box1_x1)*(box1_y2-box1_y1)
          const box2_area = (box2_x2-box2_x1)*(box2_y2-box2_y1)
          return box1_area + box2_area - intersection(box1,box2)
      }

      /**
       * Function calculates intersection area of two boxes
       * @param box1 First box in format [x1,y1,x2,y2,object_class,probability]
       * @param box2 Second box in format [x1,y1,x2,y2,object_class,probability]
       * @returns Area of intersection of the boxes as a float number
       */
      function intersection(box1,box2) {
          const [box1_x1,box1_y1,box1_x2,box1_y2] = box1;
          const [box2_x1,box2_y1,box2_x2,box2_y2] = box2;
          const x1 = Math.max(box1_x1,box2_x1);
          const y1 = Math.max(box1_y1,box2_y1);
          const x2 = Math.min(box1_x2,box2_x2);
          const y2 = Math.min(box1_y2,box2_y2);
          return (x2-x1)*(y2-y1)
      }

      /**
       * Array af skrald klasser (fra datayaml)
       */
      const yolo_classes = [
          'Aluminium foil', 'Bottle cap', 'Bottle', 'Broken glass', 'Can', 'Carton', 
          'Cigarette', 'Cup', 'Lid', 'Other litter', 'Other plastic', 'Paper', 
          'Plastic bag - wrapper', 'Plastic container', 'Pop tab', 'Straw', 
          'Styrofoam piece', 'Unlabeled litter'
      ];
    </script>
</body>
</html>
